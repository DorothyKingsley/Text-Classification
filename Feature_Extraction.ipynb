{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Next step is to create features from the raw text. The steps are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Text Cleaning** : Removing special characters,stop words, proper nouns; explanding contractions; converting the whole text to lower case.\n",
    "2. **Dictionary mapping**\n",
    "3. **Train-Test split** : For training our model and testing on unseen data\n",
    "4. **Text representation** : We will be using Tf-Idf scores to represent out data internally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/News_dataset.pickle\",'rb') as data:\n",
    "    df = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have made a contraction mapping to expand contractions in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contraction mapping to expand contractions\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defined a function to handle all precprocessing steps together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>News_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 File_Name                                            Content  Category  \\\n",
       "1   001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...  business   \n",
       "2   002.txt  Dollar gains on Greenspan speech\\n\\nThe dollar...  business   \n",
       "3   003.txt  Yukos unit buyer faces loan claim\\n\\nThe owner...  business   \n",
       "4   004.txt  High fuel prices hit BA's profits\\n\\nBritish A...  business   \n",
       "5   005.txt  Pernod takeover talk lifts Domecq\\n\\nShares in...  business   \n",
       "\n",
       "0 Complete_Filename  News_length  \n",
       "1  001.txt-business         2559  \n",
       "2  002.txt-business         2251  \n",
       "3  003.txt-business         1551  \n",
       "4  004.txt-business         2411  \n",
       "5  005.txt-business         1569  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "def text_cleaner1(text, remove_stopwords=True):\n",
    "    text = text.lower()\n",
    "    #Using Bautiful soup to remove html tags\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    #Replace contractions with their longer forms\n",
    "    #text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in text.split(\" \")])    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub('\"','', text)\n",
    "    text = re.sub(r\"'s\\b\",\"\",text)\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_content = []\n",
    "para = []\n",
    "for i in range(len(df)):\n",
    "    para = df.iloc[i]['Content']\n",
    "    clean_content.append(text_cleaner1(para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>News_length</th>\n",
       "      <th>Clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>2559</td>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>2251</td>\n",
       "      <td>dollar gains greenspan speech dollar hit highe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1551</td>\n",
       "      <td>yukos unit buyer faces loan claim owners embat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>2411</td>\n",
       "      <td>high fuel prices hit ba profits british airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1569</td>\n",
       "      <td>pernod takeover talk lifts domecq shares uk dr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 File_Name                                            Content  Category  \\\n",
       "1   001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...  business   \n",
       "2   002.txt  Dollar gains on Greenspan speech\\n\\nThe dollar...  business   \n",
       "3   003.txt  Yukos unit buyer faces loan claim\\n\\nThe owner...  business   \n",
       "4   004.txt  High fuel prices hit BA's profits\\n\\nBritish A...  business   \n",
       "5   005.txt  Pernod takeover talk lifts Domecq\\n\\nShares in...  business   \n",
       "\n",
       "0 Complete_Filename  News_length  \\\n",
       "1  001.txt-business         2559   \n",
       "2  002.txt-business         2251   \n",
       "3  003.txt-business         1551   \n",
       "4  004.txt-business         2411   \n",
       "5  005.txt-business         1569   \n",
       "\n",
       "0                                      Clean_content  \n",
       "1  ad sales boost time warner profit quarterly pr...  \n",
       "2  dollar gains greenspan speech dollar hit highe...  \n",
       "3  yukos unit buyer faces loan claim owners embat...  \n",
       "4  high fuel prices hit ba profits british airway...  \n",
       "5  pernod takeover talk lifts domecq shares uk dr...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Clean_content']=clean_content\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since stemming can produce output words that don't exist, we'll only use a lemmatization process at this moment. Lemmatization takes into consideration the morphological analysis of the words and returns words that do exist, so it will be more useful for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dorothyjeyson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dorothyjeyson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading punkt and wordnet from nltk\n",
    "nltk.download('punkt')\n",
    "print(\"=====================================================================\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = len(df)\n",
    "lemma_list = []\n",
    "for i in range(rows):\n",
    "    #create and empty list of lemmatized words\n",
    "    lemma = []\n",
    "    \n",
    "    #save the text in an object and split it into words\n",
    "    text = df.iloc[i]['Clean_content']\n",
    "    words_in_text = text.split(\" \")\n",
    "    \n",
    "    #iterate through every word\n",
    "    for word in words_in_text:\n",
    "        lemma.append(lemmatizer.lemmatize(word,pos='v'))\n",
    "    \n",
    "    #join the list\n",
    "    lemma_text = \" \".join(lemma)\n",
    "    \n",
    "    #append to lemma_list to create a new column in our existing dataframe for better readability\n",
    "    lemma_list.append(lemma_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Lemmatised_content']=lemma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>News_length</th>\n",
       "      <th>Clean_content</th>\n",
       "      <th>Lemmatised_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>2559</td>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>2251</td>\n",
       "      <td>dollar gains greenspan speech dollar hit highe...</td>\n",
       "      <td>dollar gain greenspan speech dollar hit highes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1551</td>\n",
       "      <td>yukos unit buyer faces loan claim owners embat...</td>\n",
       "      <td>yukos unit buyer face loan claim owners embatt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>2411</td>\n",
       "      <td>high fuel prices hit ba profits british airway...</td>\n",
       "      <td>high fuel price hit ba profit british airways ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1569</td>\n",
       "      <td>pernod takeover talk lifts domecq shares uk dr...</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 File_Name                                            Content  Category  \\\n",
       "1   001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...  business   \n",
       "2   002.txt  Dollar gains on Greenspan speech\\n\\nThe dollar...  business   \n",
       "3   003.txt  Yukos unit buyer faces loan claim\\n\\nThe owner...  business   \n",
       "4   004.txt  High fuel prices hit BA's profits\\n\\nBritish A...  business   \n",
       "5   005.txt  Pernod takeover talk lifts Domecq\\n\\nShares in...  business   \n",
       "\n",
       "0 Complete_Filename  News_length  \\\n",
       "1  001.txt-business         2559   \n",
       "2  002.txt-business         2251   \n",
       "3  003.txt-business         1551   \n",
       "4  004.txt-business         2411   \n",
       "5  005.txt-business         1569   \n",
       "\n",
       "0                                      Clean_content  \\\n",
       "1  ad sales boost time warner profit quarterly pr...   \n",
       "2  dollar gains greenspan speech dollar hit highe...   \n",
       "3  yukos unit buyer faces loan claim owners embat...   \n",
       "4  high fuel prices hit ba profits british airway...   \n",
       "5  pernod takeover talk lifts domecq shares uk dr...   \n",
       "\n",
       "0                                 Lemmatised_content  \n",
       "1  ad sales boost time warner profit quarterly pr...  \n",
       "2  dollar gain greenspan speech dollar hit highes...  \n",
       "3  yukos unit buyer face loan claim owners embatt...  \n",
       "4  high fuel price hit ba profit british airways ...  \n",
       "5  pernod takeover talk lift domecq share uk drin...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\\n\\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\n\\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL\\'s underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL\\'s existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\\n\\nTime Warner\\'s fourth quarter profits were slightly better than analysts\\' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\\n\\nTimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann\\'s purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad sales boost time warner profit quarterly profits us media giant timewarner jumped bn three months december year earlier firm one biggest investors google benefited sales high speed internet connections higher advert sales timewarner said fourth quarter sales rose bn bn profits buoyed one gains offset profit dip warner bros less users aol time warner said friday owns search engine google internet business aol mixed fortunes lost subscribers fourth quarter profits lower preceding three quarters however company said aol underlying profit exceptional items rose back stronger internet advertising revenues hopes increase subscribers offering online service free timewarner internet customers try sign aol existing customers high speed broadband timewarner also restate results following probe us securities exchange commission sec close concluding time warner fourth quarter profits slightly better analysts expectations film division saw profits slump helped box office flops alexander catwoman sharp contrast year earlier third final film lord rings trilogy boosted results full year timewarner posted profit bn performance revenues grew bn financial performance strong meeting exceeding full year objectives greatly enhancing flexibility chairman chief executive richard parsons said timewarner projecting operating earnings growth around also expects higher revenue wider profit margins timewarner restate accounts part efforts resolve inquiry aol us market regulators already offered pay settle charges deal review sec company said unable estimate amount needed set aside legal reserves previously set intends adjust way accounts deal german music publisher bertelsmann purchase stake aol europe reported advertising revenue book sale stake aol europe loss value stake'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['Clean_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad sales boost time warner profit quarterly profit us media giant timewarner jump bn three months december year earlier firm one biggest investors google benefit sales high speed internet connections higher advert sales timewarner say fourth quarter sales rise bn bn profit buoy one gain offset profit dip warner bros less users aol time warner say friday own search engine google internet business aol mix fortunes lose subscribers fourth quarter profit lower precede three quarter however company say aol underlie profit exceptional items rise back stronger internet advertise revenues hop increase subscribers offer online service free timewarner internet customers try sign aol exist customers high speed broadband timewarner also restate result follow probe us securities exchange commission sec close conclude time warner fourth quarter profit slightly better analysts expectations film division saw profit slump help box office flop alexander catwoman sharp contrast year earlier third final film lord ring trilogy boost result full year timewarner post profit bn performance revenues grow bn financial performance strong meet exceed full year objectives greatly enhance flexibility chairman chief executive richard parsons say timewarner project operate earn growth around also expect higher revenue wider profit margins timewarner restate account part efforts resolve inquiry aol us market regulators already offer pay settle charge deal review sec company say unable estimate amount need set aside legal reserve previously set intend adjust way account deal german music publisher bertelsmann purchase stake aol europe report advertise revenue book sale stake aol europe loss value stake'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['Lemmatised_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/miguelfzafra/Latest-News-Classifier/blob/master/0.%20Latest%20News%20Classifier/03.%20Feature%20Engineering/03.%20Feature%20Engineering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>News_length</th>\n",
       "      <th>Content_Preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>2559</td>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>2251</td>\n",
       "      <td>dollar gain greenspan speech dollar hit highes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1551</td>\n",
       "      <td>yukos unit buyer face loan claim owners embatt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>2411</td>\n",
       "      <td>high fuel price hit ba profit british airways ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1569</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 File_Name                                            Content  Category  \\\n",
       "1   001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...  business   \n",
       "2   002.txt  Dollar gains on Greenspan speech\\n\\nThe dollar...  business   \n",
       "3   003.txt  Yukos unit buyer faces loan claim\\n\\nThe owner...  business   \n",
       "4   004.txt  High fuel prices hit BA's profits\\n\\nBritish A...  business   \n",
       "5   005.txt  Pernod takeover talk lifts Domecq\\n\\nShares in...  business   \n",
       "\n",
       "0 Complete_Filename  News_length  \\\n",
       "1  001.txt-business         2559   \n",
       "2  002.txt-business         2251   \n",
       "3  003.txt-business         1551   \n",
       "4  004.txt-business         2411   \n",
       "5  005.txt-business         1569   \n",
       "\n",
       "0                               Content_Preprocessed  \n",
       "1  ad sales boost time warner profit quarterly pr...  \n",
       "2  dollar gain greenspan speech dollar hit highes...  \n",
       "3  yukos unit buyer face loan claim owners embatt...  \n",
       "4  high fuel price hit ba profit british airways ...  \n",
       "5  pernod takeover talk lift domecq share uk drin...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['File_Name', 'Content', 'Category','Complete_Filename','News_length','Lemmatised_content']\n",
    "df = df[columns]\n",
    "df = df.rename(columns={'Lemmatised_content': 'Content_Preprocessed'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_codes = {\n",
    "    'business': 0,\n",
    "    'entertainment': 1,\n",
    "    'politics': 2,\n",
    "    'sport': 3,\n",
    "    'tech': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CategoryCode']=df['Category']\n",
    "df = df.replace({'CategoryCode':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>News_length</th>\n",
       "      <th>Content_Preprocessed</th>\n",
       "      <th>CategoryCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>2559</td>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>2251</td>\n",
       "      <td>dollar gain greenspan speech dollar hit highes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1551</td>\n",
       "      <td>yukos unit buyer face loan claim owners embatt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>2411</td>\n",
       "      <td>high fuel price hit ba profit british airways ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1569</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 File_Name                                            Content  Category  \\\n",
       "1   001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...  business   \n",
       "2   002.txt  Dollar gains on Greenspan speech\\n\\nThe dollar...  business   \n",
       "3   003.txt  Yukos unit buyer faces loan claim\\n\\nThe owner...  business   \n",
       "4   004.txt  High fuel prices hit BA's profits\\n\\nBritish A...  business   \n",
       "5   005.txt  Pernod takeover talk lifts Domecq\\n\\nShares in...  business   \n",
       "\n",
       "0 Complete_Filename  News_length  \\\n",
       "1  001.txt-business         2559   \n",
       "2  002.txt-business         2251   \n",
       "3  003.txt-business         1551   \n",
       "4  004.txt-business         2411   \n",
       "5  005.txt-business         1569   \n",
       "\n",
       "0                               Content_Preprocessed  CategoryCode  \n",
       "1  ad sales boost time warner profit quarterly pr...             0  \n",
       "2  dollar gain greenspan speech dollar hit highes...             0  \n",
       "3  yukos unit buyer face loan claim owners embatt...             0  \n",
       "4  high fuel price hit ba profit british airways ...             0  \n",
       "5  pernod takeover talk lift domecq share uk drin...             0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df['Content_Preprocessed'],\n",
    "                                                    df['CategoryCode'], \n",
    "                                                    test_size = 0.15,\n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text representation\n",
    "We have various options:\n",
    "\n",
    "Count Vectors as features, TF-IDF Vectors as features, Word Embeddings as features, Text / NLP based features, Topic Models as features\n",
    "\n",
    "In this case, I am going to use TF-IDF Vectors as features. \n",
    "\n",
    "We have to define the different parameters:\n",
    "\n",
    "ngram_range: We want to consider both unigrams and bigrams.\n",
    "max_df: When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
    "min_df: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "max_features: If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "\n",
    "It needs to be mentioned that we are implicitly scaling our data when representing it as TF-IDF features with the argument norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 1\n",
    "max_df = 10\n",
    "max_features = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen these values as a first approximation. Since the models that we develop later have a very good predictive power, we'll stick to these values. But it has to be mentioned that different combinations could be tried in order to improve even more the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1796, 300)\n",
      "(317, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer(encoding='utf-8',\n",
    "    lowercase=False,\n",
    "    stop_words=None,\n",
    "    ngram_range=(1, 2),\n",
    "    max_df=10,\n",
    "    min_df=1,\n",
    "    max_features=300,\n",
    "    norm='l2',\n",
    "    sublinear_tf=False,\n",
    ")\n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = Y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.fit_transform(X_test).toarray()\n",
    "labels_test = Y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business' category:\n",
      "  . Most correlated unigrams:\n",
      ". camera\n",
      ". systems\n",
      ". seven\n",
      ". payments\n",
      ". hybrid\n",
      "  . Most correlated bigrams:\n",
      ". work pension\n",
      ". election campaign\n",
      "\n",
      "# 'entertainment' category:\n",
      "  . Most correlated unigrams:\n",
      ". broadband\n",
      ". pledge\n",
      ". students\n",
      ". takeover\n",
      ". cable\n",
      "  . Most correlated bigrams:\n",
      ". fannie mae\n",
      ". last month\n",
      "\n",
      "# 'politics' category:\n",
      "  . Most correlated unigrams:\n",
      ". la\n",
      ". ready\n",
      ". olympic\n",
      ". colleagues\n",
      ". hewitt\n",
      "  . Most correlated bigrams:\n",
      ". radio today\n",
      ". oil price\n",
      "\n",
      "# 'sport' category:\n",
      "  . Most correlated unigrams:\n",
      ". pro\n",
      ". chip\n",
      ". swiss\n",
      ". visa\n",
      ". squad\n",
      "  . Most correlated bigrams:\n",
      ". deutsche boerse\n",
      ". mr smith\n",
      "\n",
      "# 'tech' category:\n",
      "  . Most correlated unigrams:\n",
      ". goals\n",
      ". chinese\n",
      ". watchdog\n",
      ". june\n",
      ". car\n",
      "  . Most correlated bigrams:\n",
      ". blair say\n",
      ". mr straw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for product, category_id in sorted(category_codes.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(product))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anti virus',\n",
       " 'file share',\n",
       " 'house price',\n",
       " 'lib dem',\n",
       " 'music players',\n",
       " 'fannie mae',\n",
       " 'mr howard',\n",
       " 'digital music',\n",
       " 'hard drive',\n",
       " 'foreign secretary',\n",
       " 'radio today',\n",
       " 'grand slam',\n",
       " 'attorney general',\n",
       " 'liberal democrats',\n",
       " 'mr blunkett',\n",
       " 'say expect',\n",
       " 'civil service',\n",
       " 'australian open',\n",
       " 'deutsche boerse',\n",
       " 'mr smith',\n",
       " 'oil price',\n",
       " 'box office',\n",
       " 'last month',\n",
       " 'could use',\n",
       " 'work pension',\n",
       " 'election campaign',\n",
       " 'interest rat',\n",
       " 'public service',\n",
       " 'laser light',\n",
       " 'mr brown',\n",
       " 'hip hop',\n",
       " 'blair say',\n",
       " 'mr straw']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are only six. This means the unigrams have more correlation with the category than the bigrams, and since we're restricting the number of features to the most representative 300, only a few bigrams are being considered.\n",
    "\n",
    "Let's save the files we'll need in the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train\n",
    "with open('Data/X_train.pickle', 'wb') as output:\n",
    "    pickle.dump(X_train, output)\n",
    "\n",
    "#X_test\n",
    "with open('Data/X_test.pickle', 'wb') as output:\n",
    "    pickle.dump(X_test, output)\n",
    "    \n",
    "# Y_train\n",
    "with open('Data/Y_train.pickle', 'wb') as output:\n",
    "    pickle.dump(Y_train, output)\n",
    "    \n",
    "# Y_test\n",
    "with open('Data/Y_test.pickle', 'wb') as output:\n",
    "    pickle.dump(Y_test, output)\n",
    "\n",
    "# dataframe\n",
    "with open('Data/Preprocessed.pickle', 'wb') as output:\n",
    "    pickle.dump(df, output)\n",
    "    \n",
    "# features_train\n",
    "with open('Data/features_train.pickle', 'wb') as output:\n",
    "    pickle.dump(features_train, output)\n",
    "\n",
    "# labels_train\n",
    "with open('Data/labels_train.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_train, output)\n",
    "\n",
    "# features_test\n",
    "with open('Data/features_test.pickle', 'wb') as output:\n",
    "    pickle.dump(features_test, output)\n",
    "\n",
    "# labels_test\n",
    "with open('Data/labels_test.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_test, output)\n",
    "    \n",
    "# TF-IDF object\n",
    "with open('Data/tfidf.pickle', 'wb') as output:\n",
    "    pickle.dump(tfidf, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
